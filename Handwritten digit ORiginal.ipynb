{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anand\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to format which CNN expects (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "number_of_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.2885 - acc: 0.9151 - val_loss: 0.0627 - val_acc: 0.9801\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0741 - acc: 0.9777 - val_loss: 0.0411 - val_acc: 0.9865\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0545 - acc: 0.9834 - val_loss: 0.0340 - val_acc: 0.9885\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0347 - val_acc: 0.9893\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0357 - acc: 0.9886 - val_loss: 0.0264 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9895\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0259 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9923\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0193 - acc: 0.9937 - val_loss: 0.0271 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbcd53e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.027105468537213163, 0.9911]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here in first step we resize our image to mnist dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In second step we determine our mnist image to determine the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "# load the image, convert it to grayscale, and blur it to remove noise\n",
    "image = cv2.imread(\"121.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "# threshold the image\n",
    "ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# dilate the white portions\n",
    "dilate = cv2.dilate(thresh1, None, iterations=2)\n",
    "\n",
    "# find contours in the image\n",
    "cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,\n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "\n",
    "orig = image.copy()\n",
    "i = 0\n",
    "\n",
    "for cnt in cnts:\n",
    "    # Check the area of contour, if it is very small ignore it\n",
    "    if(cv2.contourArea(cnt) < 100):\n",
    "        continue\n",
    "\n",
    "    # Filtered countours are detected\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Taking ROI of the cotour\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Mark them on the image if you want\n",
    "    cv2.rectangle(orig,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    # Save your contours or characters\n",
    "    cv2.imwrite(\"roi\" + str(i) + \".png\", roi)\n",
    "\n",
    "    i = i + 1 \n",
    "\n",
    "cv2.imshow(\"Image\", orig) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I use this code\n",
    "from PIL import Image, ImageFilter\n",
    "img = Image.open('3.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "#print(img)\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
